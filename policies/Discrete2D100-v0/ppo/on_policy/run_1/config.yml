!!python/object:__main__.Args
algo: ppo
anneal_lr: false
batch_size: 1024
buffer_batches: 1
buffer_size: 1024
capture_video: false
clip_coef: 0.2
clip_vloss: true
compute_sampling_error: false
cuda: true
ent_coef: 0.01
env_id: Discrete2D100-v0
eval_episodes: 20
eval_freq: 12
exp_name: ppo_discrete
gae_lambda: 0.95
gamma: 0.99
learning_rate: 0.0003
linear: 0
max_grad_norm: 0.5
minibatch_size: 64
norm_adv: true
num_envs: 1
num_evals: 40
num_iterations: 488
num_minibatches: 16
num_steps: 1024
output_dir: policies/Discrete2D100-v0/ppo/on_policy//run_1
output_rootdir: policies
output_subdir: ''
props_batch_size: 8
props_clip_coef: 0.3
props_freeze_features: false
props_lambda: 0.0
props_learning_rate: 0.001
props_minibatch_size: 0
props_num_minibatches: 16
props_num_steps: 8
props_target_kl: 0.1
props_update_epochs: 16
run_id: 1
sampling_algo: on_policy
save_policy: true
seed: 1
target_kl: 0.03
torch_deterministic: true
total_timesteps: 500000
track: false
update_epochs: 16
vf_coef: 0.5
wandb_entity: null
wandb_project_name: cleanRL
